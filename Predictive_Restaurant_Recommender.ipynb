{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFxsDEkzdIjY96TbNrzNHy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jyothsnakopera/Predictive-Restaurant-Recommender/blob/main/Predictive_Restaurant_Recommender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Mount Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "DolERxRfBS4L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1f82831-b3e4-486e-d0df-dbdb2b228295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define paths\n",
        "train_base = \"/content/drive/MyDrive/recomendation system/Assignment/Train\"\n",
        "test_base = \"/content/drive/MyDrive/recomendation system/Assignment/Test\"  # define test folder path\n",
        "sample_submission_path = \"/content/drive/MyDrive/recomendation system/Assignment/SampleSubmission.csv\"  # define sample submission path\n",
        "\n",
        "# Load train CSVs\n",
        "orders = pd.read_csv(f\"{train_base}/orders.csv\", low_memory=False)\n",
        "train_customers = pd.read_csv(f\"{train_base}/train_customers.csv\")\n",
        "train_locations = pd.read_csv(f\"{train_base}/train_locations.csv\")\n",
        "vendors = pd.read_csv(f\"{train_base}/vendors.csv\")\n",
        "\n",
        "# Load test CSVs\n",
        "test_customers = pd.read_csv(f\"{test_base}/test_customers.csv\")\n",
        "test_locations = pd.read_csv(f\"{test_base}/test_locations.csv\")\n",
        "sample_submission = pd.read_csv(sample_submission_path)\n"
      ],
      "metadata": {
        "id": "InxQ0SlIIDUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Initial Inspection of Each DataFrame ---\n",
        "\n",
        "print(\"\\n--- Orders Data ---\")\n",
        "orders.info()\n",
        "print(\"\\nFirst 5 rows of Orders:\")\n",
        "print(orders.head())\n",
        "\n",
        "print(\"\\n--- Train Customers Data ---\")\n",
        "train_customers.info()\n",
        "print(\"\\nFirst 5 rows of Train Customers:\")\n",
        "print(train_customers.head())\n",
        "\n",
        "print(\"\\n--- Train Locations Data ---\")\n",
        "train_locations.info()\n",
        "print(\"\\nFirst 5 rows of Train Locations:\")\n",
        "print(train_locations.head())\n",
        "\n",
        "print(\"\\n--- Vendors Data ---\")\n",
        "vendors.info()\n",
        "print(\"\\nFirst 5 rows of Vendors:\")\n",
        "print(vendors.head())\n",
        "\n",
        "print(\"\\n--- Test Customers Data ---\")\n",
        "test_customers.info()\n",
        "print(\"\\nFirst 5 rows of Test Customers:\")\n",
        "print(test_customers.head())\n",
        "\n",
        "print(\"\\n--- Test Locations Data ---\")\n",
        "test_locations.info()\n",
        "print(\"\\nFirst 5 rows of Test Locations:\")\n",
        "print(test_locations.head())\n",
        "\n",
        "print(\"\\n--- Sample Submission File ---\")\n",
        "sample_submission.info()\n",
        "print(\"\\nFirst 5 rows of Sample Submission:\")\n",
        "print(sample_submission.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "og5QFQezI_Tz",
        "outputId": "2ac58a23-c033-497c-af27-148588999439"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Orders Data ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 135303 entries, 0 to 135302\n",
            "Data columns (total 26 columns):\n",
            " #   Column                          Non-Null Count   Dtype  \n",
            "---  ------                          --------------   -----  \n",
            " 0   order_id                        135233 non-null  float64\n",
            " 1   customer_id                     135303 non-null  object \n",
            " 2   item_count                      128378 non-null  float64\n",
            " 3   grand_total                     135303 non-null  float64\n",
            " 4   payment_mode                    135303 non-null  int64  \n",
            " 5   promo_code                      4305 non-null    object \n",
            " 6   vendor_discount_amount          135303 non-null  float64\n",
            " 7   promo_code_discount_percentage  65880 non-null   float64\n",
            " 8   is_favorite                     100108 non-null  object \n",
            " 9   is_rated                        135303 non-null  object \n",
            " 10  vendor_rating                   45220 non-null   float64\n",
            " 11  driver_rating                   135303 non-null  int64  \n",
            " 12  deliverydistance                135303 non-null  float64\n",
            " 13  preparationtime                 79743 non-null   float64\n",
            " 14  delivery_time                   5123 non-null    object \n",
            " 15  order_accepted_time             86955 non-null   object \n",
            " 16  driver_accepted_time            46458 non-null   object \n",
            " 17  ready_for_pickup_time           84249 non-null   object \n",
            " 18  picked_up_time                  83865 non-null   object \n",
            " 19  delivered_time                  85741 non-null   object \n",
            " 20  delivery_date                   35544 non-null   object \n",
            " 21  vendor_id                       135303 non-null  int64  \n",
            " 22  created_at                      135303 non-null  object \n",
            " 23  LOCATION_NUMBER                 135303 non-null  int64  \n",
            " 24  LOCATION_TYPE                   86410 non-null   object \n",
            " 25  CID X LOC_NUM X VENDOR          135303 non-null  object \n",
            "dtypes: float64(8), int64(4), object(14)\n",
            "memory usage: 26.8+ MB\n",
            "\n",
            "First 5 rows of Orders:\n",
            "   order_id customer_id  item_count  grand_total  payment_mode promo_code  \\\n",
            "0  163923.0     KL09J9N         6.0         10.1             1        NaN   \n",
            "1  163924.0     H5LGGFX         3.0          8.4             1        NaN   \n",
            "2  163925.0     CYLZB6T         4.0         15.0             1        NaN   \n",
            "3  163929.0     4YKUKYN         7.0         27.2             1        NaN   \n",
            "4  163930.0     WDNU30K         1.0          6.5             1        NaN   \n",
            "\n",
            "   vendor_discount_amount  promo_code_discount_percentage is_favorite  \\\n",
            "0                     0.0                             NaN         NaN   \n",
            "1                     0.0                             NaN         NaN   \n",
            "2                     0.0                             NaN         NaN   \n",
            "3                     0.0                             NaN         NaN   \n",
            "4                     0.0                             NaN         NaN   \n",
            "\n",
            "  is_rated  vendor_rating  driver_rating  deliverydistance  preparationtime  \\\n",
            "0       No            NaN              0               0.0              NaN   \n",
            "1       No            NaN              0               0.0              NaN   \n",
            "2       No            NaN              0               0.0              NaN   \n",
            "3       No            NaN              0               0.0              NaN   \n",
            "4       No            NaN              0               0.0              NaN   \n",
            "\n",
            "  delivery_time order_accepted_time driver_accepted_time  \\\n",
            "0           NaN                 NaN                  NaN   \n",
            "1           NaN                 NaN                  NaN   \n",
            "2           NaN                 NaN                  NaN   \n",
            "3           NaN                 NaN                  NaN   \n",
            "4           NaN                 NaN                  NaN   \n",
            "\n",
            "  ready_for_pickup_time picked_up_time delivered_time  delivery_date  \\\n",
            "0                   NaN            NaN            NaN  8/1/2024 5:30   \n",
            "1                   NaN            NaN            NaN  8/1/2024 5:30   \n",
            "2                   NaN            NaN            NaN  8/1/2024 5:30   \n",
            "3                   NaN            NaN            NaN  8/1/2024 5:30   \n",
            "4                   NaN            NaN            NaN  8/1/2024 5:30   \n",
            "\n",
            "   vendor_id     created_at  LOCATION_NUMBER LOCATION_TYPE  \\\n",
            "0         84  8/2/2024 5:33                0          Work   \n",
            "1         78  8/2/2024 5:34                0          Home   \n",
            "2          4  8/2/2024 5:35                0          Work   \n",
            "3        157  8/2/2024 5:39                0          Home   \n",
            "4        160  8/2/2024 5:39                0          Home   \n",
            "\n",
            "  CID X LOC_NUM X VENDOR  \n",
            "0       KL09J9N X 0 X 84  \n",
            "1       H5LGGFX X 0 X 78  \n",
            "2        CYLZB6T X 0 X 4  \n",
            "3      4YKUKYN X 0 X 157  \n",
            "4      WDNU30K X 0 X 160  \n",
            "\n",
            "--- Train Customers Data ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 34674 entries, 0 to 34673\n",
            "Data columns (total 8 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   customer_id  34674 non-null  object \n",
            " 1   gender       22520 non-null  object \n",
            " 2   dob          3046 non-null   float64\n",
            " 3   status       34674 non-null  int64  \n",
            " 4   verified     34674 non-null  int64  \n",
            " 5   language     21099 non-null  object \n",
            " 6   created_at   34674 non-null  object \n",
            " 7   updated_at   34674 non-null  object \n",
            "dtypes: float64(1), int64(2), object(5)\n",
            "memory usage: 2.1+ MB\n",
            "\n",
            "First 5 rows of Train Customers:\n",
            "  customer_id gender  dob  status  verified language       created_at  \\\n",
            "0     TCHWPBT   Male  NaN       1         1       EN   2/7/2023 19:16   \n",
            "1     ZGFSYCZ   Male  NaN       1         1       EN   2/9/2023 12:04   \n",
            "2     S2ALZFL   Male  NaN       0         1       EN  3/14/2023 18:31   \n",
            "3     952DBJQ   Male  NaN       1         1       EN  3/15/2023 19:47   \n",
            "4     1IX6FXS   Male  NaN       1         1       EN  3/15/2023 19:57   \n",
            "\n",
            "        updated_at  \n",
            "0   2/7/2023 19:16  \n",
            "1   2/9/2023 12:04  \n",
            "2  3/14/2023 18:31  \n",
            "3  3/15/2023 19:47  \n",
            "4  3/15/2023 19:57  \n",
            "\n",
            "--- Train Locations Data ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 59503 entries, 0 to 59502\n",
            "Data columns (total 5 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   customer_id      59503 non-null  object \n",
            " 1   location_number  59503 non-null  int64  \n",
            " 2   location_type    32294 non-null  object \n",
            " 3   latitude         59497 non-null  float64\n",
            " 4   longitude        59497 non-null  float64\n",
            "dtypes: float64(2), int64(1), object(2)\n",
            "memory usage: 2.3+ MB\n",
            "\n",
            "First 5 rows of Train Locations:\n",
            "  customer_id  location_number location_type  latitude  longitude\n",
            "0     02SFNJH                0           NaN  1.682392 -78.789737\n",
            "1     02SFNJH                1           NaN  1.679137   0.766823\n",
            "2     02SFNJH                2           NaN -0.498648   0.661241\n",
            "3     RU43CXC                0          Home  0.100853   0.438165\n",
            "4     BDFBPRD                0           NaN  2.523125   0.733464\n",
            "\n",
            "--- Vendors Data ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 59 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   id                    100 non-null    int64  \n",
            " 1   authentication_id     100 non-null    int64  \n",
            " 2   latitude              100 non-null    float64\n",
            " 3   longitude             100 non-null    float64\n",
            " 4   vendor_category_en    100 non-null    object \n",
            " 5   vendor_category_id    100 non-null    int64  \n",
            " 6   delivery_charge       100 non-null    float64\n",
            " 7   serving_distance      100 non-null    int64  \n",
            " 8   is_open               100 non-null    int64  \n",
            " 9   OpeningTime           91 non-null     object \n",
            " 10  OpeningTime2          91 non-null     object \n",
            " 11  prepration_time       100 non-null    int64  \n",
            " 12  commission            85 non-null     float64\n",
            " 13  is_haked_delivering   100 non-null    object \n",
            " 14  discount_percentage   100 non-null    int64  \n",
            " 15  status                100 non-null    int64  \n",
            " 16  verified              100 non-null    int64  \n",
            " 17  rank                  100 non-null    int64  \n",
            " 18  language              85 non-null     object \n",
            " 19  vendor_rating         100 non-null    float64\n",
            " 20  sunday_from_time1     99 non-null     object \n",
            " 21  sunday_to_time1       99 non-null     object \n",
            " 22  sunday_from_time2     42 non-null     object \n",
            " 23  sunday_to_time2       42 non-null     object \n",
            " 24  monday_from_time1     100 non-null    object \n",
            " 25  monday_to_time1       100 non-null    object \n",
            " 26  monday_from_time2     42 non-null     object \n",
            " 27  monday_to_time2       42 non-null     object \n",
            " 28  tuesday_from_time1    99 non-null     object \n",
            " 29  tuesday_to_time1      99 non-null     object \n",
            " 30  tuesday_from_time2    41 non-null     object \n",
            " 31  tuesday_to_time2      41 non-null     object \n",
            " 32  wednesday_from_time1  100 non-null    object \n",
            " 33  wednesday_to_time1    100 non-null    object \n",
            " 34  wednesday_from_time2  42 non-null     object \n",
            " 35  wednesday_to_time2    42 non-null     object \n",
            " 36  thursday_from_time1   99 non-null     object \n",
            " 37  thursday_to_time1     99 non-null     object \n",
            " 38  thursday_from_time2   42 non-null     object \n",
            " 39  thursday_to_time2     42 non-null     object \n",
            " 40  friday_from_time1     96 non-null     object \n",
            " 41  friday_to_time1       96 non-null     object \n",
            " 42  friday_from_time2     45 non-null     object \n",
            " 43  friday_to_time2       45 non-null     object \n",
            " 44  saturday_from_time1   98 non-null     object \n",
            " 45  saturday_to_time1     98 non-null     object \n",
            " 46  saturday_from_time2   42 non-null     object \n",
            " 47  saturday_to_time2     42 non-null     object \n",
            " 48  primary_tags          77 non-null     object \n",
            " 49  open_close_flags      100 non-null    int64  \n",
            " 50  vendor_tag            97 non-null     object \n",
            " 51  vendor_tag_name       97 non-null     object \n",
            " 52  one_click_vendor      100 non-null    object \n",
            " 53  country_id            100 non-null    int64  \n",
            " 54  city_id               100 non-null    int64  \n",
            " 55  created_at            100 non-null    object \n",
            " 56  updated_at            100 non-null    object \n",
            " 57  device_type           100 non-null    int64  \n",
            " 58  display_orders        100 non-null    int64  \n",
            "dtypes: float64(5), int64(15), object(39)\n",
            "memory usage: 46.2+ KB\n",
            "\n",
            "First 5 rows of Vendors:\n",
            "   id  authentication_id  latitude  longitude vendor_category_en  \\\n",
            "0   4             118597 -0.588596   0.754434        Restaurants   \n",
            "1  13             118608 -0.471654   0.744470        Restaurants   \n",
            "2  20             118616 -0.407527   0.643681        Restaurants   \n",
            "3  23             118619 -0.585385   0.753811        Restaurants   \n",
            "4  28             118624  0.480602   0.552850        Restaurants   \n",
            "\n",
            "   vendor_category_id  delivery_charge  serving_distance  is_open  \\\n",
            "0                   2              0.0                 6        1   \n",
            "1                   2              0.7                 5        1   \n",
            "2                   2              0.0                 8        1   \n",
            "3                   2              0.0                 5        1   \n",
            "4                   2              0.7                15        1   \n",
            "\n",
            "       OpeningTime OpeningTime2  prepration_time  commission  \\\n",
            "0  11:00AM-11:30PM            -               15         0.0   \n",
            "1  08:30AM-10:30PM            -               14         0.0   \n",
            "2  08:00AM-10:45PM            -               19         0.0   \n",
            "3  10:59AM-10:30PM            -               16         0.0   \n",
            "4  11:00AM-11:45PM            -               10         0.0   \n",
            "\n",
            "  is_haked_delivering  discount_percentage  status  verified  rank language  \\\n",
            "0                 Yes                    0       1         1    11       EN   \n",
            "1                 Yes                    0       1         1    11       EN   \n",
            "2                 Yes                    0       1         1     1       EN   \n",
            "3                 Yes                    0       1         1    11       EN   \n",
            "4                 Yes                    0       1         1    11       EN   \n",
            "\n",
            "   vendor_rating sunday_from_time1 sunday_to_time1 sunday_from_time2  \\\n",
            "0            4.4           0:00:00         0:30:00           8:00:00   \n",
            "1            4.7           0:00:00         1:30:00           8:00:00   \n",
            "2            4.5           8:00:00        22:45:00               NaN   \n",
            "3            4.5           9:00:00        23:30:00               NaN   \n",
            "4            4.4           0:01:00         0:30:00          11:00:00   \n",
            "\n",
            "  sunday_to_time2 monday_from_time1 monday_to_time1 monday_from_time2  \\\n",
            "0        23:59:00           0:00:00         0:30:00           8:00:00   \n",
            "1        23:59:00           0:00:00         1:30:00           8:00:00   \n",
            "2             NaN           8:00:00        22:45:00               NaN   \n",
            "3             NaN           9:00:00        23:30:00               NaN   \n",
            "4        23:59:00           0:01:00         0:30:00          11:00:00   \n",
            "\n",
            "  monday_to_time2 tuesday_from_time1 tuesday_to_time1 tuesday_from_time2  \\\n",
            "0        23:59:00            0:00:00          0:30:00            8:00:00   \n",
            "1        23:59:00            0:00:00          1:30:00            8:00:00   \n",
            "2             NaN            8:00:00         22:45:00                NaN   \n",
            "3             NaN            9:00:00         23:30:00                NaN   \n",
            "4        23:59:00            0:01:00          0:30:00           11:00:00   \n",
            "\n",
            "  tuesday_to_time2 wednesday_from_time1 wednesday_to_time1  \\\n",
            "0         23:59:00              0:00:00            0:30:00   \n",
            "1         23:59:00              0:00:00            1:30:00   \n",
            "2              NaN              8:00:00           22:45:00   \n",
            "3              NaN              9:00:00           23:30:00   \n",
            "4         23:59:00              0:01:00            0:30:00   \n",
            "\n",
            "  wednesday_from_time2 wednesday_to_time2 thursday_from_time1  \\\n",
            "0              8:00:00           23:59:00             0:00:00   \n",
            "1              8:00:00           19:30:00             0:00:00   \n",
            "2                  NaN                NaN             8:00:00   \n",
            "3                  NaN                NaN             9:00:00   \n",
            "4             11:00:00           23:59:00             0:01:00   \n",
            "\n",
            "  thursday_to_time1 thursday_from_time2 thursday_to_time2 friday_from_time1  \\\n",
            "0           0:30:00             8:00:00          23:59:00           0:00:00   \n",
            "1           1:30:00             8:00:00          19:30:00           0:00:00   \n",
            "2          22:45:00                 NaN               NaN           8:00:00   \n",
            "3          23:45:00                 NaN               NaN           9:00:00   \n",
            "4           0:30:00            11:00:00          23:59:00           0:01:00   \n",
            "\n",
            "  friday_to_time1 friday_from_time2 friday_to_time2 saturday_from_time1  \\\n",
            "0         0:30:00          10:00:00        23:59:00             0:00:00   \n",
            "1         1:30:00           8:00:00        23:59:00             0:00:00   \n",
            "2        22:45:00               NaN             NaN             8:00:00   \n",
            "3        23:45:00               NaN             NaN             9:00:00   \n",
            "4         1:30:00          17:45:00        23:59:00             0:01:00   \n",
            "\n",
            "  saturday_to_time1 saturday_from_time2 saturday_to_time2  \\\n",
            "0           0:30:00            10:00:00          23:59:00   \n",
            "1           1:30:00             8:00:00          23:59:00   \n",
            "2          22:45:00                 NaN               NaN   \n",
            "3          23:45:00                 NaN               NaN   \n",
            "4           1:30:00            17:45:00          23:59:00   \n",
            "\n",
            "            primary_tags  open_close_flags                 vendor_tag  \\\n",
            "0   {\"primary_tags\":\"4\"}                 1  2,4,5,8,91,22,12,24,16,23   \n",
            "1   {\"primary_tags\":\"7\"}                 1  4,41,51,34,27,15,24,16,28   \n",
            "2  {\"primary_tags\":\"71\"}                 1                  4,8,91,10   \n",
            "3  {\"primary_tags\":\"46\"}                 1                  5,8,30,24   \n",
            "4  {\"primary_tags\":\"32\"}                 1                          5   \n",
            "\n",
            "                                     vendor_tag_name one_click_vendor  \\\n",
            "0  Arabic,Breakfast,Burgers,Desserts,Free Deliver...                Y   \n",
            "1  Breakfast,Cakes,Crepes,Italian,Pasta,Pizzas,Sa...                Y   \n",
            "2            Breakfast,Desserts,Free Delivery,Indian                Y   \n",
            "3                      Burgers,Desserts,Fries,Salads                Y   \n",
            "4                                            Burgers                Y   \n",
            "\n",
            "   country_id  city_id       created_at      updated_at  device_type  \\\n",
            "0           1        1  1/30/2023 14:42  4/7/2025 15:12            3   \n",
            "1           1        1   5/3/2023 12:32  4/5/2025 20:46            3   \n",
            "2           1        1   5/4/2023 22:28  4/7/2025 16:35            3   \n",
            "3           1        1   5/6/2023 19:20   4/2/2025 0:56            3   \n",
            "4           1        1  5/17/2023 22:12  4/5/2025 15:57            3   \n",
            "\n",
            "   display_orders  \n",
            "0               1  \n",
            "1               1  \n",
            "2               1  \n",
            "3               1  \n",
            "4               1  \n",
            "\n",
            "--- Test Customers Data ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9768 entries, 0 to 9767\n",
            "Data columns (total 8 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   customer_id  9768 non-null   object \n",
            " 1   gender       6321 non-null   object \n",
            " 2   dob          848 non-null    float64\n",
            " 3   status       9768 non-null   int64  \n",
            " 4   verified     9768 non-null   int64  \n",
            " 5   language     5928 non-null   object \n",
            " 6   created_at   9768 non-null   object \n",
            " 7   updated_at   9768 non-null   object \n",
            "dtypes: float64(1), int64(2), object(5)\n",
            "memory usage: 610.6+ KB\n",
            "\n",
            "First 5 rows of Test Customers:\n",
            "  customer_id gender     dob  status  verified language       created_at  \\\n",
            "0     ICE2DJP   Male     NaN       1         1       EN   2/7/2023 16:45   \n",
            "1     FWNUI71   Male     NaN       1         1       EN  3/22/2023 20:11   \n",
            "2     LRX7BCH   Male     NaN       1         1       EN  4/17/2023 20:01   \n",
            "3     D96DHMD   Male     NaN       1         1       EN  4/29/2023 22:35   \n",
            "4     88Q8Y5V   Male  1997.0       1         1       EN   5/5/2023 12:38   \n",
            "\n",
            "        updated_at  \n",
            "0   2/7/2023 16:45  \n",
            "1  3/22/2023 20:11  \n",
            "2  4/17/2023 20:01  \n",
            "3  4/29/2023 22:35  \n",
            "4   5/5/2023 12:38  \n",
            "\n",
            "--- Test Locations Data ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 16720 entries, 0 to 16719\n",
            "Data columns (total 5 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   customer_id      16720 non-null  object \n",
            " 1   location_number  16720 non-null  int64  \n",
            " 2   location_type    9070 non-null   object \n",
            " 3   latitude         16717 non-null  float64\n",
            " 4   longitude        16717 non-null  float64\n",
            "dtypes: float64(2), int64(1), object(2)\n",
            "memory usage: 653.3+ KB\n",
            "\n",
            "First 5 rows of Test Locations:\n",
            "  customer_id  location_number location_type    latitude  longitude\n",
            "0     Z59FTQD                0           NaN  126.032278  -9.106019\n",
            "1     0JP29SK                0          Home    0.278709 -78.623847\n",
            "2     0JP29SK                1          Home    0.124485 -78.605621\n",
            "3     0JP29SK                2           NaN   -0.113891 -78.577449\n",
            "4     0JP29SK                3           NaN   -0.848796   0.136726\n",
            "\n",
            "--- Sample Submission File ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8 entries, 0 to 7\n",
            "Data columns (total 2 columns):\n",
            " #   Column                  Non-Null Count  Dtype \n",
            "---  ------                  --------------  ----- \n",
            " 0   CID X LOC_NUM X VENDOR  8 non-null      object\n",
            " 1   target                  8 non-null      int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 260.0+ bytes\n",
            "\n",
            "First 5 rows of Sample Submission:\n",
            "  CID X LOC_NUM X VENDOR  target\n",
            "0      Z59FTQD X 0 X 243       0\n",
            "1      0JP29SK X 0 X 243       0\n",
            "2      0JP29SK X 1 X 243       0\n",
            "3      0JP29SK X 2 X 243       0\n",
            "4      0JP29SK X 3 X 243       0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count missing values in 'dob' column\n",
        "train_missing_dob = train_customers['dob'].isnull().sum()\n",
        "test_missing_dob = test_customers['dob'].isnull().sum()\n",
        "\n",
        "print(f\"Missing values in 'dob' column - Train set: {train_missing_dob}\")\n",
        "print(f\"Missing values in 'dob' column - Test set: {test_missing_dob}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTKQ00hDK_cr",
        "outputId": "6373a52c-9ca2-4893-fbb5-60c2098fc038"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in 'dob' column - Train set: 31628\n",
            "Missing values in 'dob' column - Test set: 8920\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For 'dob', we can fill missing values with the median year. This is a simple imputation strategy.\n",
        "# First, calculate the median for both train and test sets and print them.\n",
        "train_median_dob = train_customers['dob'].median()\n",
        "test_median_dob = test_customers['dob'].median()\n",
        "print(f\"Train median 'dob': {train_median_dob}\")\n",
        "print(f\"Test median 'dob': {test_median_dob}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfYH38aFHt-V",
        "outputId": "70e86c15-d2a5-48b5-940a-4863ba8f925c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train median 'dob': 1993.0\n",
            "Test median 'dob': 1994.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Now fill the missing values\n",
        "train_customers['dob'].fillna(train_median_dob)\n",
        "test_customers['dob'].fillna(test_median_dob)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "AWVIW8SCLlwp",
        "outputId": "0f09e72f-6191-4167-9410-8a9607ae9732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       1994.0\n",
              "1       1994.0\n",
              "2       1994.0\n",
              "3       1994.0\n",
              "4       1997.0\n",
              "         ...  \n",
              "9763    1994.0\n",
              "9764    1994.0\n",
              "9765    1994.0\n",
              "9766    1994.0\n",
              "9767    1994.0\n",
              "Name: dob, Length: 9768, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1994.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1994.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1994.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1994.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1997.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9763</th>\n",
              "      <td>1994.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9764</th>\n",
              "      <td>1994.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9765</th>\n",
              "      <td>1994.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9766</th>\n",
              "      <td>1994.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9767</th>\n",
              "      <td>1994.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9768 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_customers['dob'].isnull().sum())  # Should print 0\n",
        "print(test_customers['dob'].isnull().sum())   # Should print 0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imlzLQhKMUUt",
        "outputId": "dfd7eeef-d213-4927-99b0-512dd4f7c911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_missing_location_type = train_locations['location_type'].isnull().sum()\n",
        "test_missing_location_type = test_locations['location_type'].isnull().sum()\n",
        "\n",
        "print(f\"Missing values in 'location_type' - Train set: {train_missing_location_type}\")\n",
        "print(f\"Missing values in 'location_type' - Test set: {test_missing_location_type}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LDyxKMvOERF",
        "outputId": "48cee1a5-9531-4943-c10f-43ab52670261"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in 'location_type' - Train set: 27209\n",
            "Missing values in 'location_type' - Test set: 7650\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_locations['location_type'] = train_locations['location_type'].fillna('Other')\n",
        "test_locations['location_type'] = test_locations['location_type'].fillna('Other')"
      ],
      "metadata": {
        "id": "PFlg5H22N2B4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_missing_lat_lon = train_locations[['latitude', 'longitude']].isnull().any(axis=1).sum()\n",
        "test_missing_lat_lon = test_locations[['latitude', 'longitude']].isnull().any(axis=1).sum()\n",
        "\n",
        "print(f\"Rows with missing latitude or longitude - Train set: {train_missing_lat_lon}\")\n",
        "print(f\"Rows with missing latitude or longitude - Test set: {test_missing_lat_lon}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdXItzZqOkvY",
        "outputId": "8d19fcd8-6f03-4eb7-b533-99a9cafedb47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows with missing latitude or longitude - Train set: 6\n",
            "Rows with missing latitude or longitude - Test set: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with missing latitude/longitude\n",
        "train_locations.dropna(subset=['latitude', 'longitude'], inplace=True)\n",
        "test_locations.dropna(subset=['latitude', 'longitude'], inplace=True)\n"
      ],
      "metadata": {
        "id": "wgRNjSm7Ov4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check missing again after drop\n",
        "train_missing_after = train_locations[['latitude', 'longitude']].isnull().any(axis=1).sum()\n",
        "test_missing_after = test_locations[['latitude', 'longitude']].isnull().any(axis=1).sum()\n",
        "\n",
        "print(f\"Missing latitude or longitude after drop - Train set: {train_missing_after}\")\n",
        "print(f\"Missing latitude or longitude after drop - Test set: {test_missing_after}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRA8Lme0Poal",
        "outputId": "8b0be8b8-e8d6-4026-941e-0b2f04fc3ebd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing latitude or longitude after drop - Train set: 0\n",
            "Missing latitude or longitude after drop - Test set: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datetime_cols = {\n",
        "    'orders': ['created_at', 'delivery_date', 'order_accepted_time', 'driver_accepted_time',\n",
        "               'ready_for_pickup_time', 'picked_up_time', 'delivered_time'],\n",
        "    'train_customers': ['created_at', 'updated_at'],\n",
        "    'test_customers': ['created_at', 'updated_at'],\n",
        "    'vendors': ['created_at', 'updated_at']\n",
        "}\n",
        "\n",
        "for df_name, cols in datetime_cols.items():\n",
        "    df = globals()[df_name]\n",
        "    for col in cols:\n",
        "        df[col] = pd.to_datetime(df[col], errors='coerce')\n"
      ],
      "metadata": {
        "id": "GOHwZiMTPuMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Verify the changes ---\n",
        "print(\"\\n--- Info for train_customers after cleaning ---\")\n",
        "train_customers.info()\n",
        "\n",
        "print(\"\\n--- Info for orders after cleaning ---\")\n",
        "orders.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gT9GYdyJQXvU",
        "outputId": "f62018df-3be5-4fb3-9e5a-f2f94267d3f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Info for train_customers after cleaning ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 34674 entries, 0 to 34673\n",
            "Data columns (total 8 columns):\n",
            " #   Column       Non-Null Count  Dtype         \n",
            "---  ------       --------------  -----         \n",
            " 0   customer_id  34674 non-null  object        \n",
            " 1   gender       22520 non-null  object        \n",
            " 2   dob          34674 non-null  float64       \n",
            " 3   status       34674 non-null  int64         \n",
            " 4   verified     34674 non-null  int64         \n",
            " 5   language     21099 non-null  object        \n",
            " 6   created_at   34555 non-null  datetime64[ns]\n",
            " 7   updated_at   34546 non-null  datetime64[ns]\n",
            "dtypes: datetime64[ns](2), float64(1), int64(2), object(3)\n",
            "memory usage: 2.1+ MB\n",
            "\n",
            "--- Info for orders after cleaning ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 135303 entries, 0 to 135302\n",
            "Data columns (total 26 columns):\n",
            " #   Column                          Non-Null Count   Dtype         \n",
            "---  ------                          --------------   -----         \n",
            " 0   order_id                        135233 non-null  float64       \n",
            " 1   customer_id                     135303 non-null  object        \n",
            " 2   item_count                      128378 non-null  float64       \n",
            " 3   grand_total                     135303 non-null  float64       \n",
            " 4   payment_mode                    135303 non-null  int64         \n",
            " 5   promo_code                      4305 non-null    object        \n",
            " 6   vendor_discount_amount          135303 non-null  float64       \n",
            " 7   promo_code_discount_percentage  65880 non-null   float64       \n",
            " 8   is_favorite                     100108 non-null  object        \n",
            " 9   is_rated                        135303 non-null  object        \n",
            " 10  vendor_rating                   45220 non-null   float64       \n",
            " 11  driver_rating                   135303 non-null  int64         \n",
            " 12  deliverydistance                135303 non-null  float64       \n",
            " 13  preparationtime                 79743 non-null   float64       \n",
            " 14  delivery_time                   5123 non-null    object        \n",
            " 15  order_accepted_time             86955 non-null   datetime64[ns]\n",
            " 16  driver_accepted_time            46458 non-null   datetime64[ns]\n",
            " 17  ready_for_pickup_time           84249 non-null   datetime64[ns]\n",
            " 18  picked_up_time                  83865 non-null   datetime64[ns]\n",
            " 19  delivered_time                  85741 non-null   datetime64[ns]\n",
            " 20  delivery_date                   35544 non-null   datetime64[ns]\n",
            " 21  vendor_id                       135303 non-null  int64         \n",
            " 22  created_at                      135303 non-null  datetime64[ns]\n",
            " 23  LOCATION_NUMBER                 135303 non-null  int64         \n",
            " 24  LOCATION_TYPE                   86410 non-null   object        \n",
            " 25  CID X LOC_NUM X VENDOR          135303 non-null  object        \n",
            "dtypes: datetime64[ns](7), float64(8), int64(4), object(7)\n",
            "memory usage: 26.8+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(orders['customer_id'].isna().sum())\n",
        "print(orders['vendor_id'].isna().sum())\n",
        "print(train_locations['location_number'].isna().sum())\n",
        "# and so on...\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcoOTie8VUJH",
        "outputId": "c790382d-9e22-422d-e47f-e8bebcce65ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "orders['customer_id'] = orders['customer_id'].astype(str)\n",
        "train_customers['customer_id'] = train_customers['customer_id'].astype(str)\n",
        "# Same for vendor_id and LOCATION_NUMBER columns\n"
      ],
      "metadata": {
        "id": "xRLLh2s6VYql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Before conversion:\")\n",
        "print(orders['customer_id'].dtype)\n",
        "print(train_customers['customer_id'].dtype)\n",
        "\n",
        "# Convert\n",
        "orders['customer_id'] = orders['customer_id'].astype(str)\n",
        "train_customers['customer_id'] = train_customers['customer_id'].astype(str)\n",
        "\n",
        "print(\"\\nAfter conversion:\")\n",
        "print(orders['customer_id'].dtype)\n",
        "print(train_customers['customer_id'].dtype)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trvsBs27Vk3K",
        "outputId": "9123f561-628a-41df-947b-b8df8851a218"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before conversion:\n",
            "object\n",
            "object\n",
            "\n",
            "After conversion:\n",
            "object\n",
            "object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Merge 1: Combine orders with customer information ---\n",
        "# We use a 'left' merge to ensure we keep all orders, even if a customer's details are missing.\n",
        "train_df = pd.merge(orders, train_customers, on='customer_id', how='left')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6v66hg6RRkuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Merge 2: Add customer location data ---\n",
        "# We need to match not just the customer, but the specific location number for that order.\n",
        "# Note: We need to rename the 'location_number' column in train_locations before merging to avoid conflicts.\n",
        "train_df = pd.merge(train_df, train_locations.rename(columns={'location_number': 'LOCATION_NUMBER'}),\n",
        "                    on=['customer_id', 'LOCATION_NUMBER'], how='left')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5gIbEJijV03i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Merge 3: Add vendor information ---\n",
        "# The 'id' column in the vendors table corresponds to 'vendor_id' in the orders table.\n",
        "train_df = pd.merge(train_df, vendors.rename(columns={'id': 'vendor_id'}),\n",
        "                    on='vendor_id', how='left')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yC6jYoNMV4Eo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Verify the final merged DataFrame ---\n",
        "print(\"✅ All training data has been merged successfully!\")\n",
        "print(\"\\n--- Info for the final merged training DataFrame ---\")\n",
        "train_df.info()\n",
        "\n",
        "\n",
        "# Note: You might see suffixes like '_x' and '_y' on column names.\n",
        "# This happens when you merge dataframes that have columns with the same name (e.g., 'created_at').\n",
        "# Pandas adds these suffixes to keep them distinct."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKCg3wH0V6Z6",
        "outputId": "d1309a0e-8fe2-4674-9ad3-40bddad0a7a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All training data has been merged successfully!\n",
            "\n",
            "--- Info for the final merged training DataFrame ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 135502 entries, 0 to 135501\n",
            "Data columns (total 94 columns):\n",
            " #   Column                          Non-Null Count   Dtype         \n",
            "---  ------                          --------------   -----         \n",
            " 0   order_id                        135432 non-null  float64       \n",
            " 1   customer_id                     135502 non-null  object        \n",
            " 2   item_count                      128577 non-null  float64       \n",
            " 3   grand_total                     135502 non-null  float64       \n",
            " 4   payment_mode                    135502 non-null  int64         \n",
            " 5   promo_code                      4325 non-null    object        \n",
            " 6   vendor_discount_amount          135502 non-null  float64       \n",
            " 7   promo_code_discount_percentage  66040 non-null   float64       \n",
            " 8   is_favorite                     100307 non-null  object        \n",
            " 9   is_rated                        135502 non-null  object        \n",
            " 10  vendor_rating_x                 45269 non-null   float64       \n",
            " 11  driver_rating                   135502 non-null  int64         \n",
            " 12  deliverydistance                135502 non-null  float64       \n",
            " 13  preparationtime                 79942 non-null   float64       \n",
            " 14  delivery_time                   5132 non-null    object        \n",
            " 15  order_accepted_time             87154 non-null   datetime64[ns]\n",
            " 16  driver_accepted_time            46577 non-null   datetime64[ns]\n",
            " 17  ready_for_pickup_time           84437 non-null   datetime64[ns]\n",
            " 18  picked_up_time                  84056 non-null   datetime64[ns]\n",
            " 19  delivered_time                  85937 non-null   datetime64[ns]\n",
            " 20  delivery_date                   35544 non-null   datetime64[ns]\n",
            " 21  vendor_id                       135502 non-null  int64         \n",
            " 22  created_at_x                    135502 non-null  datetime64[ns]\n",
            " 23  LOCATION_NUMBER                 135502 non-null  int64         \n",
            " 24  LOCATION_TYPE                   86526 non-null   object        \n",
            " 25  CID X LOC_NUM X VENDOR          135502 non-null  object        \n",
            " 26  gender                          104748 non-null  object        \n",
            " 27  dob                             132226 non-null  float64       \n",
            " 28  status_x                        132226 non-null  float64       \n",
            " 29  verified_x                      132226 non-null  float64       \n",
            " 30  language_x                      110463 non-null  object        \n",
            " 31  created_at_y                    132164 non-null  datetime64[ns]\n",
            " 32  updated_at_x                    132139 non-null  datetime64[ns]\n",
            " 33  location_type                   135497 non-null  object        \n",
            " 34  latitude_x                      135497 non-null  float64       \n",
            " 35  longitude_x                     135497 non-null  float64       \n",
            " 36  authentication_id               135502 non-null  int64         \n",
            " 37  latitude_y                      135502 non-null  float64       \n",
            " 38  longitude_y                     135502 non-null  float64       \n",
            " 39  vendor_category_en              135502 non-null  object        \n",
            " 40  vendor_category_id              135502 non-null  int64         \n",
            " 41  delivery_charge                 135502 non-null  float64       \n",
            " 42  serving_distance                135502 non-null  int64         \n",
            " 43  is_open                         135502 non-null  int64         \n",
            " 44  OpeningTime                     126491 non-null  object        \n",
            " 45  OpeningTime2                    126491 non-null  object        \n",
            " 46  prepration_time                 135502 non-null  int64         \n",
            " 47  commission                      120167 non-null  float64       \n",
            " 48  is_haked_delivering             135502 non-null  object        \n",
            " 49  discount_percentage             135502 non-null  int64         \n",
            " 50  status_y                        135502 non-null  int64         \n",
            " 51  verified_y                      135502 non-null  int64         \n",
            " 52  rank                            135502 non-null  int64         \n",
            " 53  language_y                      120167 non-null  object        \n",
            " 54  vendor_rating_y                 135502 non-null  float64       \n",
            " 55  sunday_from_time1               134692 non-null  object        \n",
            " 56  sunday_to_time1                 134692 non-null  object        \n",
            " 57  sunday_from_time2               57477 non-null   object        \n",
            " 58  sunday_to_time2                 57477 non-null   object        \n",
            " 59  monday_from_time1               135502 non-null  object        \n",
            " 60  monday_to_time1                 135502 non-null  object        \n",
            " 61  monday_from_time2               57477 non-null   object        \n",
            " 62  monday_to_time2                 57477 non-null   object        \n",
            " 63  tuesday_from_time1              134692 non-null  object        \n",
            " 64  tuesday_to_time1                134692 non-null  object        \n",
            " 65  tuesday_from_time2              56870 non-null   object        \n",
            " 66  tuesday_to_time2                56870 non-null   object        \n",
            " 67  wednesday_from_time1            135502 non-null  object        \n",
            " 68  wednesday_to_time1              135502 non-null  object        \n",
            " 69  wednesday_from_time2            57680 non-null   object        \n",
            " 70  wednesday_to_time2              57680 non-null   object        \n",
            " 71  thursday_from_time1             134692 non-null  object        \n",
            " 72  thursday_to_time1               134692 non-null  object        \n",
            " 73  thursday_from_time2             57477 non-null   object        \n",
            " 74  thursday_to_time2               57477 non-null   object        \n",
            " 75  friday_from_time1               132377 non-null  object        \n",
            " 76  friday_to_time1                 132377 non-null  object        \n",
            " 77  friday_from_time2               61201 non-null   object        \n",
            " 78  friday_to_time2                 61201 non-null   object        \n",
            " 79  saturday_from_time1             133853 non-null  object        \n",
            " 80  saturday_to_time1               133853 non-null  object        \n",
            " 81  saturday_from_time2             62364 non-null   object        \n",
            " 82  saturday_to_time2               62364 non-null   object        \n",
            " 83  primary_tags                    106687 non-null  object        \n",
            " 84  open_close_flags                135502 non-null  int64         \n",
            " 85  vendor_tag                      133321 non-null  object        \n",
            " 86  vendor_tag_name                 133321 non-null  object        \n",
            " 87  one_click_vendor                135502 non-null  object        \n",
            " 88  country_id                      135502 non-null  int64         \n",
            " 89  city_id                         135502 non-null  int64         \n",
            " 90  created_at                      135502 non-null  datetime64[ns]\n",
            " 91  updated_at_y                    135502 non-null  datetime64[ns]\n",
            " 92  device_type                     135502 non-null  int64         \n",
            " 93  display_orders                  135502 non-null  int64         \n",
            "dtypes: datetime64[ns](11), float64(18), int64(18), object(47)\n",
            "memory usage: 97.2+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display_cols = ['customer_id', 'order_id', 'grand_total', 'vendor_id', 'vendor_rating_x', 'dob', 'latitude_x', 'longitude_x', 'vendor_tag_name']\n",
        "print(train_df[display_cols].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpRaQwPEV7bS",
        "outputId": "ee949670-40d6-41bf-df11-faf3b5d42077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  customer_id  order_id  grand_total  vendor_id  vendor_rating_x     dob  \\\n",
            "0     KL09J9N  163923.0         10.1         84              NaN  1993.0   \n",
            "1     H5LGGFX  163924.0          8.4         78              NaN  1993.0   \n",
            "2     CYLZB6T  163925.0         15.0          4              NaN  1993.0   \n",
            "3     4YKUKYN  163929.0         27.2        157              NaN  1993.0   \n",
            "4     WDNU30K  163930.0          6.5        160              NaN  1993.0   \n",
            "\n",
            "   latitude_x  longitude_x                                    vendor_tag_name  \n",
            "0   -0.090650   -78.580196                   Burgers,Fries,Kids meal,Shawarma  \n",
            "1    1.733950   -78.795830  Pizzas,Italian,Breakfast,Soups,Pasta,Salads,De...  \n",
            "2   -0.368541   -78.547354  Arabic,Breakfast,Burgers,Desserts,Free Deliver...  \n",
            "3    0.421104   -78.640676      Biryani,Desserts,Indian,Rice,Thali,Vegetarian  \n",
            "4   -0.704372   -78.507665              American,Burgers,Kids meal,Sandwiches  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Get a count of missing values for each column ---\n",
        "missing_counts = train_df.isnull().sum()\n",
        "print(\"--- Missing Values Count in Merged DataFrame ---\")\n",
        "# Display columns that have at least one missing value\n",
        "print(missing_counts[missing_counts > 0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SzSe-1dWGoA",
        "outputId": "d4a4e93c-9c08-450b-87d9-074b657cac98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Missing Values Count in Merged DataFrame ---\n",
            "order_id                              70\n",
            "item_count                          6925\n",
            "promo_code                        131177\n",
            "promo_code_discount_percentage     69462\n",
            "is_favorite                        35195\n",
            "vendor_rating_x                    90233\n",
            "preparationtime                    55560\n",
            "delivery_time                     130370\n",
            "order_accepted_time                48348\n",
            "driver_accepted_time               88925\n",
            "ready_for_pickup_time              51065\n",
            "picked_up_time                     51446\n",
            "delivered_time                     49565\n",
            "delivery_date                      99958\n",
            "LOCATION_TYPE                      48976\n",
            "gender                             30754\n",
            "dob                                 3276\n",
            "status_x                            3276\n",
            "verified_x                          3276\n",
            "language_x                         25039\n",
            "created_at_y                        3338\n",
            "updated_at_x                        3363\n",
            "location_type                          5\n",
            "latitude_x                             5\n",
            "longitude_x                            5\n",
            "OpeningTime                         9011\n",
            "OpeningTime2                        9011\n",
            "commission                         15335\n",
            "language_y                         15335\n",
            "sunday_from_time1                    810\n",
            "sunday_to_time1                      810\n",
            "sunday_from_time2                  78025\n",
            "sunday_to_time2                    78025\n",
            "monday_from_time2                  78025\n",
            "monday_to_time2                    78025\n",
            "tuesday_from_time1                   810\n",
            "tuesday_to_time1                     810\n",
            "tuesday_from_time2                 78632\n",
            "tuesday_to_time2                   78632\n",
            "wednesday_from_time2               77822\n",
            "wednesday_to_time2                 77822\n",
            "thursday_from_time1                  810\n",
            "thursday_to_time1                    810\n",
            "thursday_from_time2                78025\n",
            "thursday_to_time2                  78025\n",
            "friday_from_time1                   3125\n",
            "friday_to_time1                     3125\n",
            "friday_from_time2                  74301\n",
            "friday_to_time2                    74301\n",
            "saturday_from_time1                 1649\n",
            "saturday_to_time1                   1649\n",
            "saturday_from_time2                73138\n",
            "saturday_to_time2                  73138\n",
            "primary_tags                       28815\n",
            "vendor_tag                          2181\n",
            "vendor_tag_name                     2181\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Drop Columns with Too Many Missing Values ---\n",
        "# If a column is missing >50% of its data, it's often better to remove it.\n",
        "cols_to_drop = [\n",
        "    'promo_code', 'promo_code_discount_percentage', 'delivery_time',\n",
        "    'driver_accepted_time', 'sunday_from_time2', 'sunday_to_time2',\n",
        "    'monday_from_time2', 'monday_to_time2', 'tuesday_from_time2', 'tuesday_to_time2',\n",
        "    'wednesday_from_time2', 'wednesday_to_time2', 'thursday_from_time2', 'thursday_to_time2',\n",
        "    'friday_from_time2', 'friday_to_time2', 'saturday_from_time2', 'saturday_to_time2'\n",
        "]\n",
        "train_df.drop(columns=cols_to_drop, inplace=True)\n",
        "print(f\"✅ Dropped {len(cols_to_drop)} columns with high percentage of missing values.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3U4SytPaXihU",
        "outputId": "a430dfa6-153b-41e4-8c9f-87c958224f04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dropped 18 columns with high percentage of missing values.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Impute Numeric Columns with Median ---\n",
        "# Median is robust to outliers and is a good choice for vendor ratings, time, etc.\n",
        "numeric_cols_to_fill = [\n",
        "    'order_id', 'item_count', 'vendor_rating_x', 'preparationtime',\n",
        "    'dob', 'status_x', 'verified_x', 'commission'\n",
        "]\n",
        "for col in numeric_cols_to_fill:\n",
        "    if col in train_df.columns:\n",
        "        median_val = train_df[col].median()\n",
        "        train_df[col] = train_df[col].fillna(median_val)\n",
        "print(\"✅ Imputed key numeric columns with their median.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0DvU-4-YMo_",
        "outputId": "c8bb424d-f0ae-4cb2-85b5-6201ba8c811b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Imputed key numeric columns with their median.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Impute Categorical Columns with Mode ---\n",
        "categorical_cols_to_fill = [\n",
        "    'is_favorite', 'LOCATION_TYPE', 'gender', 'language_x',\n",
        "    'vendor_tag', 'vendor_tag_name', 'primary_tags'\n",
        "]\n",
        "for col in categorical_cols_to_fill:\n",
        "     if col in train_df.columns:\n",
        "        mode_val = train_df[col].mode()[0]\n",
        "        train_df[col] = train_df[col].fillna(mode_val)\n",
        "\n",
        "print(\"✅ Imputed key categorical columns with their mode.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYFsRi2BYqEW",
        "outputId": "1c3815de-bf7b-49df-943c-9da2804df526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Imputed key categorical columns with their mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Drop Rows with Critical Missing Info ---\n",
        "train_df.dropna(subset=['latitude_x', 'longitude_x', 'order_accepted_time'], inplace=True)\n",
        "print(\"✅ Dropped rows where essential data was missing.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpeAKzyHYv7z",
        "outputId": "5d415eed-f243-4543-e881-757843958b99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dropped rows where essential data was missing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. Final Verification ---\n",
        "print(\"\\n--- Final Check for Missing Values ---\")\n",
        "missing_counts_after_cleaning = train_df.isnull().sum()\n",
        "final_missing = missing_counts_after_cleaning[missing_counts_after_cleaning > 0]\n",
        "\n",
        "if final_missing.empty:\n",
        "    print(\"\\nNo missing values remain. Your data is clean! 🎉\")\n",
        "else:\n",
        "    print(\"\\nRemaining missing values:\")\n",
        "    print(final_missing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qs7E__0uZLse",
        "outputId": "c8cba13b-6a4c-4286-8865-24493c7f0cd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Final Check for Missing Values ---\n",
            "\n",
            "Remaining missing values:\n",
            "ready_for_pickup_time     2746\n",
            "picked_up_time            3134\n",
            "delivered_time            1322\n",
            "delivery_date            87154\n",
            "created_at_y              2201\n",
            "updated_at_x              2221\n",
            "OpeningTime               8919\n",
            "OpeningTime2              8919\n",
            "language_y               15185\n",
            "sunday_from_time1           56\n",
            "sunday_to_time1             56\n",
            "tuesday_from_time1          56\n",
            "tuesday_to_time1            56\n",
            "thursday_from_time1         56\n",
            "thursday_to_time1           56\n",
            "friday_from_time1         1712\n",
            "friday_to_time1           1712\n",
            "saturday_from_time1        378\n",
            "saturday_to_time1          378\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Drop the delivery_date column ---\n",
        "# It has too many missing values to be reliable.\n",
        "if 'delivery_date' in train_df.columns:\n",
        "    train_df.drop(columns=['delivery_date'], inplace=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "BvH3xICfZOqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This method fills a NaN with the last valid observation. It's good for sequential data.\n",
        "time_cols_to_ffill = [\n",
        "    'ready_for_pickup_time', 'picked_up_time', 'delivered_time',\n",
        "    'created_at_y', 'updated_at_x'\n",
        "]\n",
        "for col in time_cols_to_ffill:\n",
        "    if col in train_df.columns:\n",
        "        train_df[col].ffill()\n",
        "        # In case the very first rows are NaN, bfill will fill them from the next valid one.\n",
        "        train_df[col].bfill(inplace=True)"
      ],
      "metadata": {
        "id": "DTJzDupLaBao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mode_fill_cols = [\n",
        "    'OpeningTime', 'OpeningTime2', 'language_y', 'sunday_from_time1',\n",
        "    'sunday_to_time1', 'tuesday_from_time1', 'tuesday_to_time1',\n",
        "    'thursday_from_time1', 'thursday_to_time1', 'friday_from_time1',\n",
        "    'friday_to_time1', 'saturday_from_time1', 'saturday_to_time1'\n",
        "]\n",
        "for col in mode_fill_cols:\n",
        "    if col in train_df.columns:\n",
        "        mode_val = train_df[col].mode()[0]\n",
        "        train_df[col] = train_df[col].fillna(mode_val)"
      ],
      "metadata": {
        "id": "0O80AfXwaNdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Final, Final Check for Missing Values ---\")\n",
        "final_missing_check = train_df.isnull().sum().sum()\n",
        "\n",
        "if final_missing_check == 0:\n",
        "    print(\"\\nSuccess! All missing values have been handled. Your data is now completely clean.\")\n",
        "else:\n",
        "    print(f\"\\nStill found {final_missing_check} missing values. Please review the remaining columns.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sv1GmN88adSK",
        "outputId": "3e0b947d-ebdd-4b1f-a676-89dd913795e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Final, Final Check for Missing Values ---\n",
            "\n",
            "Success! All missing values have been handled. Your data is now completely clean.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# STEP 4: FEATURE ENGINEERING\n",
        "# This part was missed. It creates the columns that caused the error.\n",
        "\n",
        "print(\"Running Feature Engineering...\")\n",
        "# 1. Customer Age\n",
        "current_year = datetime.now().year\n",
        "train_df['customer_age'] = current_year - train_df['dob']\n",
        "\n",
        "# 2. Haversine Distance\n",
        "def haversine_distance(lat1, lon1, lat2, lon2):\n",
        "    return np.sqrt((lat2 - lat1)**2 + (lon2 - lon1)**2)\n",
        "\n",
        "train_df['distance_km'] = haversine_distance(\n",
        "    train_df['latitude_x'], train_df['longitude_x'],\n",
        "    train_df['latitude_y'], train_df['longitude_y']\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_FrXwEFah8d",
        "outputId": "7eda7eea-01f2-43b2-df5e-f43a20296dba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Feature Engineering...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Time-Based Features\n",
        "train_df['order_hour'] = train_df['created_at_x'].dt.hour\n",
        "train_df['order_day_of_week'] = train_df['created_at_x'].dt.dayofweek # Monday=0, Sunday=6\n",
        "\n",
        "# 4. Fill any NaNs that might have been created\n",
        "train_df['customer_age'].fillna(train_df['customer_age'].median())\n",
        "train_df['distance_km'].fillna(train_df['distance_km'].median())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "kDg_8s_Ha6zR",
        "outputId": "5174019c-60ea-4d95-ddb7-2bcf996c602a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38819     209.815604\n",
              "38820       0.396242\n",
              "38821       0.534822\n",
              "38822       0.535882\n",
              "38823       0.363061\n",
              "             ...    \n",
              "135148      0.031578\n",
              "135149      1.117884\n",
              "135150      0.247597\n",
              "135151      0.206146\n",
              "135152      0.162903\n",
              "Name: distance_km, Length: 87154, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>distance_km</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>38819</th>\n",
              "      <td>209.815604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38820</th>\n",
              "      <td>0.396242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38821</th>\n",
              "      <td>0.534822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38822</th>\n",
              "      <td>0.535882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38823</th>\n",
              "      <td>0.363061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135148</th>\n",
              "      <td>0.031578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135149</th>\n",
              "      <td>1.117884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135150</th>\n",
              "      <td>0.247597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135151</th>\n",
              "      <td>0.206146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135152</th>\n",
              "      <td>0.162903</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>87154 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Feature Selection\n",
        "features = [\n",
        "    'customer_id', 'vendor_id', 'item_count', 'grand_total',\n",
        "    'vendor_discount_amount', 'is_favorite', 'vendor_rating_x',\n",
        "    'driver_rating', 'deliverydistance', 'preparationtime',\n",
        "    'gender', 'customer_age', 'location_type', 'distance_km',\n",
        "    'order_hour', 'order_day_of_week', 'vendor_category_en',\n",
        "    'serving_distance', 'is_open', 'prepration_time', 'commission',\n",
        "    'rank', 'vendor_tag_name', 'city_id'\n",
        "]\n",
        "\n",
        "model_df = train_df[features].copy()\n",
        "model_df['target'] = 1 # All existing orders are positive examples\n",
        "\n"
      ],
      "metadata": {
        "id": "AviJSVvBbZ4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Encoding Categorical Features\n",
        "categorical_cols = model_df.select_dtypes(include=['object', 'category']).columns\n",
        "print(f\"Columns to be encoded: {list(categorical_cols)}\")\n",
        "\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    model_df[col] = le.fit_transform(model_df[col])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZXT1sM0bzJ5",
        "outputId": "2b6dba3b-2191-410e-fb80-bd1f2aad1a93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns to be encoded: ['customer_id', 'is_favorite', 'gender', 'location_type', 'vendor_category_en', 'vendor_tag_name']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(model_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcyXiUPjb1xd",
        "outputId": "f80152cf-bca7-43da-e3f8-83aad12ed301"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       customer_id  vendor_id  item_count  grand_total  \\\n",
            "38819          347        231         3.0         10.6   \n",
            "38820         5461         20         3.0         12.5   \n",
            "38821        14090          4         2.0         10.6   \n",
            "38822         1170          4         1.0          9.8   \n",
            "38823         2473        274         1.0          7.9   \n",
            "\n",
            "       vendor_discount_amount  is_favorite  vendor_rating_x  driver_rating  \\\n",
            "38819                     0.0            0              0.0              0   \n",
            "38820                     0.0            0              0.0              0   \n",
            "38821                     0.0            0              0.0              0   \n",
            "38822                     0.0            1              5.0              5   \n",
            "38823                     0.0            0              0.0              0   \n",
            "\n",
            "       deliverydistance  preparationtime  gender  customer_age  location_type  \\\n",
            "38819               0.0             45.0       6          32.0              2   \n",
            "38820               0.0             45.0       6          32.0              2   \n",
            "38821               0.0             45.0       6          32.0              2   \n",
            "38822               0.0             45.0       6          32.0              2   \n",
            "38823               0.0             45.0       6          32.0              1   \n",
            "\n",
            "       distance_km  order_hour  order_day_of_week  vendor_category_en  \\\n",
            "38819   209.815604           9                  2                   1   \n",
            "38820     0.396242           9                  2                   0   \n",
            "38821     0.534822          10                  2                   0   \n",
            "38822     0.535882          10                  2                   0   \n",
            "38823     0.363061          10                  2                   1   \n",
            "\n",
            "       serving_distance  is_open  prepration_time  commission  rank  \\\n",
            "38819                10        1               15         0.0    11   \n",
            "38820                 8        1               19         0.0     1   \n",
            "38821                 6        1               15         0.0    11   \n",
            "38822                 6        1               15         0.0    11   \n",
            "38823                15        0               45         0.0    11   \n",
            "\n",
            "       vendor_tag_name  city_id  target  \n",
            "38819                8        1       1  \n",
            "38820               37        1       1  \n",
            "38821               19        1       1  \n",
            "38822               19        1       1  \n",
            "38823               54        1       1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "kJTCAFPrb5HS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Create Negative Samples ---\n",
        "print(\"Creating negative samples...\")\n",
        "all_customers = model_df['customer_id'].unique()\n",
        "all_vendors = model_df['vendor_id'].unique()\n",
        "existing_pairs = set(zip(model_df['customer_id'], model_df['vendor_id']))\n",
        "\n",
        "negative_samples = []\n",
        "# Create a 1:1 ratio of positive to negative samples\n",
        "num_negative_samples = len(model_df)\n",
        "\n",
        "while len(negative_samples) < num_negative_samples:\n",
        "    customer = np.random.choice(all_customers)\n",
        "    vendor = np.random.choice(all_vendors)\n",
        "    if (customer, vendor) not in existing_pairs:\n",
        "        # For negative samples, we use typical or neutral values.\n",
        "        sample = {\n",
        "            'customer_id': customer,\n",
        "            'vendor_id': vendor,\n",
        "            'item_count': model_df['item_count'].median(),\n",
        "            'grand_total': 0,\n",
        "            'vendor_discount_amount': 0,\n",
        "            'is_favorite': 0,\n",
        "            'vendor_rating_x': model_df['vendor_rating_x'].median(),\n",
        "            'driver_rating': 0,\n",
        "            'deliverydistance': model_df['deliverydistance'].median(),\n",
        "            'preparationtime': model_df['preparationtime'].median(),\n",
        "            'gender': model_df['gender'].mode()[0],\n",
        "            'customer_age': model_df['customer_age'].median(),\n",
        "            'location_type': model_df['location_type'].mode()[0],\n",
        "            'distance_km': model_df['distance_km'].median(),\n",
        "            'order_hour': 12, # A neutral hour of the day\n",
        "            'order_day_of_week': 3, # A neutral day of the week\n",
        "            'vendor_category_en': model_df['vendor_category_en'].mode()[0],\n",
        "            'serving_distance': model_df['serving_distance'].median(),\n",
        "            'is_open': 1,\n",
        "            'prepration_time': model_df['prepration_time'].median(),\n",
        "            'commission': model_df['commission'].median(),\n",
        "            'rank': model_df['rank'].median(),\n",
        "            'vendor_tag_name': model_df['vendor_tag_name'].mode()[0],\n",
        "            'city_id': model_df['city_id'].mode()[0],\n",
        "            'target': 0 # Target is 0 for non-orders\n",
        "        }\n",
        "        negative_samples.append(sample)\n",
        "        # Add to set to avoid creating duplicate negative samples\n",
        "        existing_pairs.add((customer, vendor))\n",
        "\n",
        "negative_df = pd.DataFrame(negative_samples)\n",
        "print(f\"✅ Created {len(negative_df)} negative samples.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7HgE8SwcR4D",
        "outputId": "7dd37fa4-cb94-4067-e83e-d9c5a8330d42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating negative samples...\n",
            "✅ Created 87154 negative samples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Combine and Prepare Final Dataset ---\n",
        "print(\"Combining positive and negative samples...\")\n",
        "final_df = pd.concat([model_df, negative_df], ignore_index=True)\n",
        "# Shuffle the dataset to mix positive and negative samples\n",
        "final_df = final_df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = final_df.drop(columns=['target'])\n",
        "y = final_df['target']\n",
        "\n",
        "# Split data for training and validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(\"✅ Final dataset prepared and split.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCt6Q8nycs75",
        "outputId": "09eef6ec-6380-4eaa-cff5-dd62d8f6b70a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combining positive and negative samples...\n",
            "✅ Final dataset prepared and split.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Train the LightGBM Model ---\n",
        "print(\"Training LightGBM model...\")\n",
        "\n",
        "# Define model parameters\n",
        "params = {\n",
        "    'objective': 'binary',\n",
        "    'metric': 'auc', # AUC is a great metric for this type of problem\n",
        "    'boosting_type': 'gbdt',\n",
        "    'n_estimators': 1000,\n",
        "    'learning_rate': 0.05,\n",
        "    'num_leaves': 31,\n",
        "    'max_depth': -1,\n",
        "    'seed': 42,\n",
        "    'n_jobs': -1,\n",
        "    'verbose': -1,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'subsample': 0.8,\n",
        "}\n",
        "\n",
        "model = lgb.LGBMClassifier(**params)\n",
        "\n",
        "# Train the model with a callback for early stopping\n",
        "model.fit(X_train, y_train,\n",
        "          eval_set=[(X_val, y_val)],\n",
        "          eval_metric='auc',\n",
        "          callbacks=[lgb.early_stopping(100, verbose=True)])\n",
        "\n",
        "print(\"\\n🎉 Model training complete! You now have a trained recommendation engine.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Grrmd1QNih8R",
        "outputId": "507b1fe0-62dc-498b-8554-ef510b7a965c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training LightGBM model...\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "Early stopping, best iteration is:\n",
            "[3]\tvalid_0's auc: 1\n",
            "\n",
            "🎉 Model training complete! You now have a trained recommendation engine.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# --- 1. Load All Necessary Data ---\n",
        "print(\"Loading all necessary data...\")\n",
        "test_customers = pd.read_csv('/content/drive/MyDrive/recomendation system/Assignment/Test/test_customers.csv')\n",
        "test_locations = pd.read_csv('/content/drive/MyDrive/recomendation system/Assignment/Test/test_locations.csv')\n",
        "vendors = pd.read_csv('/content/drive/MyDrive/recomendation system/Assignment/Train/vendors.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFcnuovfiuAg",
        "outputId": "4b98113f-01c6-4d4a-d50a-d060e8bd0a20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading all necessary data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Create All Customer-Vendor Combinations for the Test Set ---\n",
        "print(\"Generating test combinations...\")\n",
        "all_vendor_ids = vendors['id'].unique()\n",
        "test_locations['key'] = 1\n",
        "all_vendors_df = pd.DataFrame({'vendor_id': all_vendor_ids, 'key': 1})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nx-Suqz5jYwZ",
        "outputId": "0050a1ab-5cde-44d9-d2b7-3a2bac589d9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating test combinations...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Master test dataframe\n",
        "test_df = pd.merge(test_locations, all_vendors_df, on='key').drop('key', axis=1)\n",
        "test_df = pd.merge(test_df, test_customers, on='customer_id', how='left')\n",
        "test_df = pd.merge(test_df, vendors.rename(columns={'id': 'vendor_id'}), on='vendor_id', how='left')\n",
        "print(f\"Created {len(test_df)} combinations for prediction.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwfnfEpajgVe",
        "outputId": "a650d9d6-53a5-4f9e-e7e6-5dc7eec91bb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 1673600 combinations for prediction.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Create Placeholder Columns & Apply Feature Engineering (FIXES THE ERROR) ---\n",
        "print(\"Applying feature engineering and creating placeholder columns...\")\n",
        "\n",
        "# Create columns from the training set that don't exist in the test set\n",
        "# and fill them with neutral/median values. This is CRITICAL.\n",
        "for col in features:\n",
        "    if col not in test_df.columns and col != 'target':\n",
        "        # Use a sensible default, like the median from the training data (model_df)\n",
        "        test_df[col] = model_df[col].median()\n",
        "\n",
        "# Now, apply the same feature engineering as before\n",
        "current_year = datetime.now().year\n",
        "test_df['customer_age'] = current_year - test_df['dob']\n",
        "test_df['distance_km'] = np.sqrt((test_df['latitude_y'] - test_df['latitude_x'])**2 + (test_df['longitude_y'] - test_df['longitude_x'])**2)\n",
        "test_df['order_hour'] = 18  # Assume a peak evening hour\n",
        "test_df['order_day_of_week'] = 5 # Assume a Friday\n",
        "\n",
        "print(\"✅ Feature engineering for test set is complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c-X4OOzji5P",
        "outputId": "9584588b-62e6-49e8-e8b7-5894e4c4e005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying feature engineering and creating placeholder columns...\n",
            "✅ Feature engineering for test set is complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Clean, Fill NaNs, and Encode ---\n",
        "print(\"Cleaning and encoding test data...\")\n",
        "final_test_df = test_df[features].copy() # This will now work without a KeyError\n",
        "\n",
        "# Fill any remaining NaNs\n",
        "for col in final_test_df.columns:\n",
        "    if final_test_df[col].isnull().any():\n",
        "        if final_test_df[col].dtype.kind in 'ifc': # Numeric columns\n",
        "            fill_value = model_df[col].median()\n",
        "        else: # Categorical columns\n",
        "            fill_value = model_df[col].mode()[0]\n",
        "        final_test_df[col].fillna(fill_value, inplace=True)\n",
        "\n",
        "# Encode categorical columns using the label encoders fitted on the training data\n",
        "for col in categorical_cols:\n",
        "    # Load the encoder fitted on the original training data\n",
        "    le = LabelEncoder()\n",
        "    le.fit(model_df[col]) # Fit on the original model_df's column\n",
        "\n",
        "    # Transform the test data, handling any new, unseen labels\n",
        "    # We map unseen labels to a special value like -1 or the most frequent class\n",
        "    final_test_df[col] = final_test_df[col].map(lambda s: s if s in le.classes_ else le.classes_[0])\n",
        "    final_test_df[col] = le.transform(final_test_df[col])\n",
        "\n",
        "print(\"✅ Cleaning and encoding for test set is complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1T9AXGvTjnGJ",
        "outputId": "9f875fbd-7e95-4cd1-e0e1-f13febdf55b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaning and encoding test data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-945358993.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  final_test_df[col].fillna(fill_value, inplace=True)\n",
            "/tmp/ipython-input-945358993.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  final_test_df[col].fillna(fill_value, inplace=True)\n",
            "/tmp/ipython-input-945358993.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  final_test_df[col].fillna(fill_value, inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Cleaning and encoding for test set is complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. Make Predictions ---\n",
        "print(\"Making predictions...\")\n",
        "# Ensure column order matches the training data (X)\n",
        "final_test_df = final_test_df[X.columns]\n",
        "predictions = model.predict_proba(final_test_df)[:, 1] # Probability of '1'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaMS63QFjscN",
        "outputId": "a0a27b9b-537d-4597-b76a-d9ab71e10bb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Making predictions...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6. Generate Submission File ---\n",
        "print(\"Generating submission file...\")\n",
        "submission_df = test_df[['customer_id', 'location_number', 'vendor_id']].copy()\n",
        "submission_df['CID X LOC_NUM X VENDOR'] = submission_df['customer_id'] + ' X ' + submission_df['location_number'].astype(str) + ' X ' + submission_df['vendor_id'].astype(str)\n",
        "submission_df['target'] = (predictions > 0.5).astype(int) # Convert probability to binary 0 or 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygsMfUs6kjn5",
        "outputId": "6f610c51-678d-4b65-bb41-3629b6d47940"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating submission file...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to CSV\n",
        "submission_df[['CID X LOC_NUM X VENDOR', 'target']].to_csv('submission.csv', index=False)\n",
        "\n",
        "\n",
        "print(submission_df[['CID X LOC_NUM X VENDOR', 'target']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tK5-cpnwkm1n",
        "outputId": "dd6f807e-58b9-4352-ebd3-569f58fc8679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  CID X LOC_NUM X VENDOR  target\n",
            "0        Z59FTQD X 0 X 4       1\n",
            "1       Z59FTQD X 0 X 13       1\n",
            "2       Z59FTQD X 0 X 20       1\n",
            "3       Z59FTQD X 0 X 23       1\n",
            "4       Z59FTQD X 0 X 28       1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WP3v7_jEnD5G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}